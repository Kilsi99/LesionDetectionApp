# -*- coding: utf-8 -*-
"""Classification_task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-B3OWcxy3vYUkyGVeJ3ZhFcsJWBxW006
"""

!pip install segmentation-models-pytorch --quiet
!pip install wandb --quiet

import torch
import torchvision
import matplotlib.pyplot as plt
import numpy as np
import os
import re
from google.colab import drive
drive.mount('/content/drive')
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler, TensorDataset, Subset
from PIL import Image
from torch.optim.lr_scheduler import ReduceLROnPlateau
import cv2
from google.colab.patches import cv2_imshow as imshow
from PIL import Image
from torchvision import transforms as T
import segmentation_models_pytorch as SMP
import wandb
import torch.nn.functional as F
import pandas as pd
import torchvision.models as models
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight

wandb.login()

main_dir = '/content/drive/MyDrive/Deployment_project/ham_images'
data = pd.read_csv('/content/drive/MyDrive/Deployment_project/HAM10000_metadata.csv')

class ClassificationDataset(Dataset):
    def __init__(self, data, main_dir, img_transforms=None):
        self.data = data.reset_index(drop=True)
        self.img_transforms = img_transforms
        self.main_dir = main_dir

        self.label_to_index = {'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3, 'akiec': 4, 'vasc': 5, 'df': 6}

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        row = self.data.iloc[index]
        label_str = row['dx']
        label_num = self.label_to_index[label_str]

        image_id = re.findall(r'\d{7}', row['image_id'])[0]
        img_path = os.path.join(self.main_dir, f'ISIC_{image_id}.jpg')
        image = Image.open(img_path).convert('RGB')

        if self.img_transforms:
            image = self.img_transforms(image)

        return {"image": image, "label": torch.tensor(label_num, dtype=torch.long)}

img_transformations = T.Compose([T.Resize((256,256)),
                                 T.RandomHorizontalFlip(),
                                 T.RandomVerticalFlip(),
                                 T.RandomRotation(degrees = 15),
                                 T.ToTensor(),
                                 T.Normalize(mean = [0.485, 0.456, 0.406], std  = [0.229, 0.224, 0.225])])

mask_transformations = T.Compose([T.Resize((256,256), interpolation=T.InterpolationMode.NEAREST),
                                  T.ToTensor()])

test_img_transform = T.Compose([T.Resize((256,256)),
                                T.ToTensor(),
                                T.Normalize(mean = [0.485, 0.456, 0.406], std  = [0.229, 0.224, 0.225])])

cls_df = data
cls_df, _ = train_test_split(cls_df,train_size=5000,stratify=cls_df['dx'],random_state=42)
Classification_Dataset = ClassificationDataset(cls_df, main_dir, img_transformations)

cls_subset = Classification_Dataset

cls_dataset_size = len(cls_subset)
cls_indices = list(range(cls_dataset_size))


train_size = int(0.6 * cls_dataset_size)
val_size = int(0.2 * cls_dataset_size)
test_size = cls_dataset_size - train_size - val_size

train_indices, temp_indices = train_test_split(
    cls_indices,
    test_size=(val_size + test_size),
    random_state=42
)

val_indices, test_indices = train_test_split(
    temp_indices,
    test_size=test_size / (val_size + test_size),
    random_state=42
)


train_cls_dataset = Subset(cls_subset, train_indices)
val_cls_dataset = Subset(cls_subset, val_indices)
test_cls_dataset = Subset(cls_subset, test_indices)


batch_size = 8

train_cls_loader = DataLoader(train_cls_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
val_cls_loader = DataLoader(val_cls_dataset, batch_size=batch_size, shuffle=False, num_workers=4)
test_cls_loader = DataLoader(test_cls_dataset, batch_size=batch_size, shuffle=False, num_workers=4)

class ResNet50Classifier(nn.Module):
    def __init__(self, num_classes=7, pretrained=True):
        super().__init__()
        self.model = models.resnet50(pretrained=pretrained)
        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)

    def forward(self, x):
        return self.model(x)

model = ResNet50Classifier(7, True)

for param in model.model.parameters():
    param.requires_grad = False

for param in model.model.fc.parameters():
    param.requires_grad = True

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
train_df = Classification_Dataset.data.loc[train_indices]

label_to_index = {'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3, 'akiec': 4, 'vasc': 5, 'df': 6}
y = [label_to_index[label] for label in train_df['dx']]

class_weights = compute_class_weight(
    class_weight="balanced",
    classes=np.unique(y),
    y=y
)

class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)
print("Class Weights:", class_weights)

cls_criterion = nn.CrossEntropyLoss(weight = class_weights)
optimiser = optim.Adam(model.parameters(), lr = 1e-3)

def calculate_cls_accuracy(preds, labels):
    """Classification accuracy"""
    predicted_classes = torch.argmax(preds, dim=1)
    return (predicted_classes == labels).float().mean()


def train_classification_model(model,
                               classification_loader,
                               val_classification_loader,
                               cls_criterion,
                               optimiser,
                               device='cuda',
                               project_name='Classification_Project',
                               num_epochs=15):

    model.to(device)
    scheduler = ReduceLROnPlateau(optimiser, mode="min", factor=0.5, patience=3)

    wandb.init(project=project_name, config={
        "epochs": num_epochs,
        "optimiser": optimiser.__class__.__name__,
        "cls_loss": cls_criterion.__class__.__name__,
        "architecture": model.__class__.__name__,
    }, mode="online")

    history = {
        "train_cls_loss": [], "train_cls_acc": [],
        "val_cls_loss": [], "val_cls_acc": []
    }

    for epoch in range(num_epochs):
        model.train()
        epoch_cls_loss, epoch_cls_acc = [], []

        for cls_batch in classification_loader:
            imgs_cls = cls_batch["image"].to(device)
            labels_cls = cls_batch["label"].to(device)

            cls_preds = model(imgs_cls)
            cls_loss = cls_criterion(cls_preds, labels_cls)

            optimiser.zero_grad()
            cls_loss.backward()
            optimiser.step()

            cls_acc = calculate_cls_accuracy(cls_preds, labels_cls)
            epoch_cls_loss.append(cls_loss.item())
            epoch_cls_acc.append(cls_acc.item())

        avg_cls_loss = sum(epoch_cls_loss) / len(epoch_cls_loss)
        avg_cls_acc = sum(epoch_cls_acc) / len(epoch_cls_acc)

        history["train_cls_loss"].append(avg_cls_loss)
        history["train_cls_acc"].append(avg_cls_acc)

        model.eval()
        val_cls_loss, val_cls_acc = [], []

        with torch.no_grad():
            for cls_batch in val_classification_loader:
                imgs_cls = cls_batch["image"].to(device)
                labels_cls = cls_batch["label"].to(device)

                cls_preds = model(imgs_cls)
                cls_loss = cls_criterion(cls_preds, labels_cls)
                cls_acc = calculate_cls_accuracy(cls_preds, labels_cls)

                val_cls_loss.append(cls_loss.item())
                val_cls_acc.append(cls_acc.item())

        avg_val_cls_loss = sum(val_cls_loss) / len(val_cls_loss)
        avg_val_cls_acc = sum(val_cls_acc) / len(val_cls_acc)

        history["val_cls_loss"].append(avg_val_cls_loss)
        history["val_cls_acc"].append(avg_val_cls_acc)

        scheduler.step(avg_val_cls_loss)

        print(f"Epoch [{epoch+1}/{num_epochs}]")
        print(f"  Train - Cls Loss: {avg_cls_loss:.4f}, Cls Acc: {avg_cls_acc:.4f}")
        print(f"  Val   - Cls Loss: {avg_val_cls_loss:.4f}, Cls Acc: {avg_val_cls_acc:.4f}")

        wandb.log({
            "train_cls_loss": avg_cls_loss,
            "train_cls_acc": avg_cls_acc,
            "val_cls_loss": avg_val_cls_loss,
            "val_cls_acc": avg_val_cls_acc,
            "epoch": epoch + 1
        })

    wandb.finish()
    return history

train_classification_model(model,
                          train_cls_loader,
                          val_cls_loader,
                          cls_criterion,
                          optimiser,
                          device='cuda',
                          project_name='Classification_Project',
                          num_epochs=10)

train_classification_model(model,
                          train_cls_loader,
                          val_cls_loader,
                          cls_criterion,
                          optimiser,
                          device='cuda',
                          project_name='Classification_Project',
                          num_epochs=20)

def evaluate_classification_model(model, cls_loader, project_name='Classification_Project', device='cuda'):
    model.to(device)
    model.eval()

    all_cls_loss, all_cls_acc = [], []

    wandb.init(project=project_name, name="test_run")

    with torch.no_grad():
        for cls_batch in cls_loader:
            imgs = cls_batch["image"].to(device)
            labels = cls_batch["label"].to(device)

            preds = model(imgs)
            cls_loss = F.cross_entropy(preds, labels)
            cls_acc = calculate_cls_accuracy(preds, labels)

            all_cls_loss.append(cls_loss.item())
            all_cls_acc.append(cls_acc.item())

    avg_cls_loss = sum(all_cls_loss) / len(all_cls_loss)
    avg_cls_acc = sum(all_cls_acc) / len(all_cls_acc)

    wandb.log({
        "test_cls_loss": avg_cls_loss,
        "test_cls_acc": avg_cls_acc
    })

    print(f"Test Classification - Loss: {avg_cls_loss:.4f}, Accuracy: {avg_cls_acc:.4f}")

    wandb.finish()

    return {
        "test_cls_loss": avg_cls_loss,
        "test_cls_acc": avg_cls_acc
    }

evaluate_classification_model(model, test_cls_loader, project_name='Classification_Project', device='cuda')

save_dir = '/content/drive/MyDrive/Deployment_project/models'

def save_model(save_dir, model_name, model):
  """Saves the model's state dictionary."""
  save_path = os.path.join(save_dir,model_name)
  torch.save(model.state_dict(), save_path)

  print(f'Model state dictionary saved at: {save_path}')

save_model(save_dir, 'Lesion_classification_Resnet50_state_dict.pth', model)

class ResNet50Classifier(nn.Module):
    def __init__(self, num_classes=7, pretrained=True):
        super().__init__()
        self.model = models.resnet50(pretrained=pretrained)
        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)

    def forward(self, x):
        return self.model(x)

model = ResNet50Classifier(7, True)


def load_model(load_path):
  """Loads a model from a state dictionary."""
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  model.load_state_dict(torch.load(load_path, map_location=device))
  model.to(device)

  return model

load_path = '/content/drive/MyDrive/Deployment_project/models/Lesion_classification_Resnet50_state_dict.pth'
model = load_model(load_path)

test_img_dir = '/content/drive/MyDrive/Deployment_project/ISBI2016_ISIC_Part1_Test_Data/ISBI2016_ISIC_Part1_Test_Data'
test_mask_dir = '/content/drive/MyDrive/Deployment_project/ISBI2016_ISIC_Part1_Test_GroundTruth/ISBI2016_ISIC_Part1_Test_GroundTruth'

def load_PIL_image(image_dir, mask_dir, num):
  image_names = os.listdir(image_dir)
  text =  image_names[num]
  matches = re.findall(r'\d{7}', text)

  image_path = os.path.join(image_dir, text)

  img = Image.open(image_path).convert('RGB')

  return img

image = load_PIL_image(test_img_dir, test_mask_dir, 8)

img_transform = T.Compose([
    T.Resize((256,256)),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
boot_image = img_transform(image).unsqueeze(0).to(device)

model.eval()
with torch.no_grad():
    output = model(boot_image)

pred_class = torch.argmax(output, dim=1).item()


model.train()
probs_list = []
for i in range(100):
    probs = torch.softmax(model(boot_image), dim=1).detach().cpu().numpy()
    probs_list.append(probs[0, pred_class])

ci_lower = np.percentile(probs_list, 2.5)
ci_upper = np.percentile(probs_list, 97.5)

print(f"Predicted class: {pred_class}")
print(f"Mean confidence: {np.mean(probs_list):.4f}")
print(f"95% Confidence interval: [{ci_lower:.4f}, {ci_upper:.4f}]")

def model_inference(model, img, device = 'cpu'):
  w, h = img.size
  test_img_transform = T.Compose([T.Resize((256,256)),
                                T.ToTensor(),
                                T.Normalize(mean = [0.485, 0.456, 0.406], std  = [0.229, 0.224, 0.225])])

  img = test_img_transform(img).to(device)
  model.eval()
  with torch.no_grad():
    cls_logits = model(img.unsqueeze(0))
    cls_pred = torch.argmax(cls_logits, dim=1).item()

  return  cls_pred

image = load_PIL_image(test_img_dir, test_mask_dir, 23)
cls = model_inference(model, image)
classes = {0:'nv', 1:'mel', 2:'bkl', 3:'bcc', 4:'akiec', 5:'vasc', 6:'df'}
classes[cls]

# Transforms the image to a tensor and adds the batch dimention
def Image_transform(img):
  test_img_transform = T.Compose([T.Resize((256,256)),
                                T.ToTensor(),
                                T.Normalize(mean = [0.485, 0.456, 0.406], std  = [0.229, 0.224, 0.225])])
  img = test_img_transform(img)
  return img.unsqueeze(0)

img = Image_transform(image)
img.shape

# Extracts the last convolutional layer from the model
target_layer = model.model.layer4[-1].conv3

# define the forward hook that will collect the activations from the final convolution layer
def forward_hook(module, input, output):
  global activations
  activations = output

# Defines the hook that will collect the gradient with wrt the layers output
def backward_hook(module, grad_in, grad_out):
  global gradients
  gradients = grad_out[0]

# Registers the hook on the target layer
forward_handle = target_layer.register_forward_hook(forward_hook)
backward_handle = target_layer.register_backward_hook(backward_hook)

output = model(img) # Outputs logits from the model
pred_class = output.argmax(dim=1).item() # Seects the preducted class
pred_class

model.zero_grad() # Zeros the gradient to not mess up caculations
one_hot = torch.zeros_like(output) # Creates an empty tesnor same shape as output
one_hot[0, pred_class] = 1 # ceates one hot tensor setting the predicted class to 1
output.backward(gradient = one_hot) # abckpropgate only the gradient of the predicted class

pooled_grads = torch.mean(gradients, dim= [0,2,3]) # finds the mean of the gradients for each feature map
cam = torch.zeros(activations.shape[2:], dtype=torch.float32) # Creates an empty tensor
pooled_grads.shape

# Finds the weighted sum of all the heatmaps creating a class activation map that will be upsampled to final resolution
for i,w in enumerate(pooled_grads):
  cam += w * activations[0, i]

cam =  F.relu(cam) # only postive contributions remain
cam = cam - cam.min()
cam = cam/ cam.max() # Normalise for visualisation
cam = cam.detach().numpy()

cam_resized = cv2.resize(cam, (256, 256))
heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)
heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
to_pil = T.ToPILImage()
img_pil = to_pil(img.squeeze(0))
img_resized = np.array(img_pil.resize((256, 256)))
overlay = heatmap * 0.4 + img_resized * 0.6

plt.figure(figsize=(6,6))
plt.imshow(overlay.astype(np.uint8))
plt.axis("off")
plt.title(f"Grad-CAM (Predicted class: {pred_class})")
plt.show()

plt.imshow(image)