# -*- coding: utf-8 -*-
"""Segmentation_task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SYZw0NJS8kbsUG6iFmDe9bBcMgEjaVEH
"""

!pip install segmentation-models-pytorch --quiet
!pip install wandb --quiet

import torch
import torchvision
import matplotlib.pyplot as plt
import numpy as np
import os
import re
from google.colab import drive
drive.mount('/content/drive')
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler, TensorDataset, Subset
from PIL import Image
from torch.optim.lr_scheduler import ReduceLROnPlateau
import cv2
from google.colab.patches import cv2_imshow as imshow
from PIL import Image
from torchvision import transforms as T
import segmentation_models_pytorch as SMP
import wandb
import torch.nn.functional as F
import pandas as pd
import torchvision.models as models
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight

wandb.login()

train_img_dir = '/content/drive/MyDrive/Deployment_project/ISBI2016_ISIC_Part1_Training_Data/ISBI2016_ISIC_Part1_Training_Data'
train_mask_dir = '/content/drive/MyDrive/Deployment_project/ISBI2016_ISIC_Part1_Training_GroundTruth/ISBI2016_ISIC_Part1_Training_GroundTruth'
test_img_dir = '/content/drive/MyDrive/Deployment_project/ISBI2016_ISIC_Part1_Test_Data/ISBI2016_ISIC_Part1_Test_Data'
test_mask_dir = '/content/drive/MyDrive/Deployment_project/ISBI2016_ISIC_Part1_Test_GroundTruth/ISBI2016_ISIC_Part1_Test_GroundTruth'

def load_image(image_dir, mask_dir, num):
  image_names = os.listdir(image_dir)
  text =  image_names[num]
  matches = re.findall(r'\d{7}', text)

  image_path = os.path.join(image_dir, text)
  mask_path = os.path.join(mask_dir, f'ISIC_{matches[0]}_Segmentation.png')

  img = cv2.imread(image_path)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  mask = cv2.imread(mask_path)
  mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)

  return img, mask


def mask_overlay(img_dir,mask_dir, num, colour = (0,255,0), alpha = 0.5):
  img, mask = load_image(img_dir, mask_dir, num)
  mask = mask.astype(np.uint8)
  mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)

  coloured_mask = cv2.bitwise_and(mask, colour)
  overlay = cv2.addWeighted(img, alpha, coloured_mask, 1-alpha, 0)
  plt.imshow(overlay)

mask_overlay(train_img_dir, train_mask_dir, 500, (0,255,0), 0.9)

class SegmentationDataset(Dataset):
  def __init__(self, img_dir, mask_dir,img_transforms = None, mask_transforms = None):
    self.img_dir = img_dir
    self.mask_dir = mask_dir
    self.img_transforms = img_transforms
    self.mask_transforms = mask_transforms
    self.image_names = os.listdir(img_dir)

  def __len__(self):
    return len(self.image_names)

  def __getitem__(self, index):
    if index < len(self.image_names):
      text = self.image_names[index]
      matches = re.findall(r'\d{7}', text)

      img_path = os.path.join(self.img_dir, text)
      mask_path = os.path.join(self.mask_dir, f'ISIC_{matches[0]}_Segmentation.png')

      img = Image.open(img_path).convert('RGB')
      if self.img_transforms:
        img = self.img_transforms(img)

      mask = Image.open(mask_path).convert('L')
      if self.mask_transforms:
        mask = self.mask_transforms(mask)

      return {'image': img, 'mask': mask}

img_transformations = T.Compose([T.Resize((256,256)),
                                 T.RandomHorizontalFlip(),
                                 T.RandomVerticalFlip(),
                                 T.RandomRotation(degrees = 15),
                                 T.ToTensor(),
                                 T.Normalize(mean = [0.485, 0.456, 0.406], std  = [0.229, 0.224, 0.225])])

mask_transformations = T.Compose([T.Resize((256,256), interpolation=T.InterpolationMode.NEAREST),
                                  T.ToTensor()])

test_img_transform = T.Compose([T.Resize((256,256)),
                                T.ToTensor(),
                                T.Normalize(mean = [0.485, 0.456, 0.406], std  = [0.229, 0.224, 0.225])])

Segmentation_Dataset = SegmentationDataset(train_img_dir,train_mask_dir, img_transformations, mask_transformations)

seg_dataset_size = len(Segmentation_Dataset)
train_size = int(0.8 * seg_dataset_size)
val_size = (seg_dataset_size - train_size)//2
test_size = val_size

train_seg_dataset, val_seg_dataset,  test_seg_dataset= random_split(Segmentation_Dataset,[train_size, val_size, test_size],generator=torch.Generator().manual_seed(42))
batch_size = 8

train_seg_loader = DataLoader(train_seg_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
val_seg_loader = DataLoader(val_seg_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
test_seg_loader = DataLoader(test_seg_dataset, batch_size = batch_size, shuffle = False, num_workers = 2)

model = SMP.DeepLabV3Plus(
      encoder_name="resnet50",
      encoder_weights=None,
      in_channels=3,
      classes=2
  )

for param in model.encoder.parameters():
  param.requires_grad = True

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
seg_criterion  = nn.CrossEntropyLoss()
optimiser = optim.Adam(model.parameters(), lr = 1e-3)

def calculate_seg_accuracy(preds, masks):

    predicted_classes = torch.argmax(preds, dim=1)  # (B, H, W)
    return (predicted_classes == masks.squeeze(1)).float().mean()


def dice_coef(preds, masks, smooth=1e-5):

    probs = torch.softmax(preds, dim=1)                  # (B, C, H, W)
    masks_onehot = F.one_hot(
        masks.squeeze(1).long(), num_classes=probs.shape[1]
    ).permute(0, 3, 1, 2).float()                        # (B, C, H, W)

    intersection = (probs * masks_onehot).sum(dim=(2, 3))
    union = probs.sum(dim=(2, 3)) + masks_onehot.sum(dim=(2, 3))
    dice = (2 * intersection + smooth) / (union + smooth)

    return dice.mean()

def train_segmentation(model,
                       train_loader, val_loader,
                       seg_criterion, optimiser,
                       device="cuda",
                       project_name="Segmentation_Project",
                       num_epochs=15):

    model.to(device)
    scheduler = ReduceLROnPlateau(optimiser, mode="min", factor=0.5, patience=3)

    wandb.init(project=project_name, config={
        "epochs": num_epochs,
        "optimiser": optimiser.__class__.__name__,
        "seg_loss": seg_criterion.__class__.__name__,
        "architecture": model.__class__.__name__,
    }, mode="online")

    history = {
        "train_seg_loss": [], "train_seg_acc": [], "train_dice": [],
        "val_seg_loss": [], "val_seg_acc": [], "val_dice": []
    }

    for epoch in range(num_epochs):
        model.train()
        epoch_seg_loss, epoch_seg_acc, epoch_dice = [], [], []


        for batch in train_loader:
            imgs = batch["image"].to(device)
            masks = batch["mask"].to(device)

            seg_preds = model(imgs)
            seg_loss = seg_criterion(seg_preds, masks.squeeze(1).long())

            optimiser.zero_grad()
            seg_loss.backward()
            optimiser.step()

            seg_acc = calculate_seg_accuracy(seg_preds, masks)
            dice = dice_coef(seg_preds, masks)

            epoch_seg_loss.append(seg_loss.item())
            epoch_seg_acc.append(seg_acc.item())
            epoch_dice.append(dice.item())


        avg_seg_loss = sum(epoch_seg_loss) / len(epoch_seg_loss)
        avg_seg_acc = sum(epoch_seg_acc) / len(epoch_seg_acc)
        avg_dice = sum(epoch_dice) / len(epoch_dice)

        history["train_seg_loss"].append(avg_seg_loss)
        history["train_seg_acc"].append(avg_seg_acc)
        history["train_dice"].append(avg_dice)


        model.eval()
        val_seg_loss, val_seg_acc, val_dice = [], [], []

        with torch.no_grad():
            for batch in val_loader:
                imgs = batch["image"].to(device)
                masks = batch["mask"].to(device)

                seg_preds = model(imgs)
                seg_loss = seg_criterion(seg_preds, masks.squeeze(1).long())

                seg_acc = calculate_seg_accuracy(seg_preds, masks)
                dice = dice_coef(seg_preds, masks)

                val_seg_loss.append(seg_loss.item())
                val_seg_acc.append(seg_acc.item())
                val_dice.append(dice.item())

        avg_val_seg_loss = sum(val_seg_loss) / len(val_seg_loss)
        avg_val_seg_acc = sum(val_seg_acc) / len(val_seg_acc)
        avg_val_dice = sum(val_dice) / len(val_dice)

        history["val_seg_loss"].append(avg_val_seg_loss)
        history["val_seg_acc"].append(avg_val_seg_acc)
        history["val_dice"].append(avg_val_dice)

        scheduler.step(avg_val_seg_loss)


        print(f"Epoch [{epoch+1}/{num_epochs}]")
        print(f"  Train - Seg Loss: {avg_seg_loss:.4f}, Seg Acc: {avg_seg_acc:.4f}, Dice: {avg_dice:.4f}")
        print(f"  Val   - Seg Loss: {avg_val_seg_loss:.4f}, Seg Acc: {avg_val_seg_acc:.4f}, Dice: {avg_val_dice:.4f}")

        wandb.log({
            "train_seg_loss": avg_seg_loss,
            "train_seg_acc": avg_seg_acc,
            "train_dice": avg_dice,
            "val_seg_loss": avg_val_seg_loss,
            "val_seg_acc": avg_val_seg_acc,
            "val_dice": avg_val_dice,
            "epoch": epoch + 1
        })

    wandb.finish()
    return history

train_segmentation(model, train_seg_loader, val_seg_loader, seg_criterion, optimiser, device, 'Segmentation Project', 10)

train_segmentation(model, train_seg_loader, val_seg_loader, seg_criterion, optimiser, device, 'Segmentation Project', 20)

def evaluate_model(model, seg_loader, project_name='Segmentation_Project', device='cuda'):
    model.to(device)
    model.eval()

    all_seg_loss, all_seg_acc, all_dice = [], [], []


    wandb.init(project=project_name, name="test_run")

    with torch.no_grad():
        for seg_batch in seg_loader:
            imgs_seg = seg_batch["image"].to(device)
            masks_seg = seg_batch["mask"].to(device)

            seg_preds = model(imgs_seg)
            seg_loss = F.cross_entropy(seg_preds, masks_seg.squeeze(1).long())

            seg_acc = calculate_seg_accuracy(seg_preds, masks_seg)
            dice = dice_coef(seg_preds, masks_seg)

            all_seg_loss.append(seg_loss.item())
            all_seg_acc.append(seg_acc.item())
            all_dice.append(dice.item())


    avg_seg_loss = sum(all_seg_loss) / len(all_seg_loss)
    avg_seg_acc = sum(all_seg_acc) / len(all_seg_acc)
    avg_dice = sum(all_dice) / len(all_dice)


    wandb.log({
        "test_seg_loss": avg_seg_loss,
        "test_seg_acc": avg_seg_acc,
        "test_dice": avg_dice
    })

    print(f"Test Segmentation - Loss: {avg_seg_loss:.4f}, "
          f"Accuracy: {avg_seg_acc:.4f}, Dice: {avg_dice:.4f}")

    wandb.finish()

    return {
        "test_seg_loss": avg_seg_loss,
        "test_seg_acc": avg_seg_acc,
        "test_dice": avg_dice
    }

evaluate_model(model, test_seg_loader, project_name='Segmentation_Project', device=device)

save_dir = '/content/drive/MyDrive/Deployment_project/models'

def save_model(save_dir, model_name, model):
  """Saves the model's state dictionary."""
  save_path = os.path.join(save_dir,model_name)
  torch.save(model.state_dict(), save_path)

  print(f'Model state dictionary saved at: {save_path}')

save_model(save_dir, 'Lesion_segmentation_Resnet50_state_dict.pth', model)

def load_model(load_path):
  """Loads a model from a state dictionary."""
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


  model = SMP.DeepLabV3Plus(
      encoder_name="resnet50",
      encoder_weights=None,
      in_channels=3,
      classes=2
  )


  model.load_state_dict(torch.load(load_path, map_location=device))
  model.to(device)

  return model

load_path = '/content/drive/MyDrive/Deployment_project/models/Lesion_segmentation_Resnet50_state_dict.pth'
model = load_model(load_path)

def load_PIL_image(image_dir, mask_dir, num):
  image_names = os.listdir(image_dir)
  text =  image_names[num]
  matches = re.findall(r'\d{7}', text)

  image_path = os.path.join(image_dir, text)
  mask_path = os.path.join(mask_dir, f'ISIC_{matches[0]}_Segmentation.png')

  img = Image.open(image_path).convert('RGB')
  mask = Image.open(mask_path).convert('L')

  return img, mask

image, mask = load_PIL_image(test_img_dir, test_mask_dir, 8)

def model_inference_seg(model, img, transform, device="cuda"):

    w, h = img.size
    img = transform(img).to(device)

    model.eval()
    with torch.no_grad():
        logits = model(img.unsqueeze(0))
        pred_mask = torch.argmax(logits, dim=1)


    pred_mask = pred_mask.unsqueeze(1).float()
    resized_mask = F.interpolate(pred_mask, size=(h, w), mode='nearest')
    resized_mask = resized_mask.squeeze(1)

    return resized_mask

def overlay_mask(image, mask, colour = (0,255,0), alpha = 0.9):
  image = np.array(image)
  print(image.shape)
  mask = mask.squeeze().cpu().numpy().astype(np.uint8)
  mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB) * 255
  print(mask.shape)

  coloured_mask = cv2.bitwise_and(mask, colour)
  print(coloured_mask.shape)
  overlay = cv2.addWeighted(image, alpha, coloured_mask, 1-alpha, 0)
  plt.imshow(overlay)
  plt.axis('off')

image, mask = load_PIL_image(test_img_dir, test_mask_dir, 64)
mask = model_inference_seg(model, image, test_img_transform)
overlay_mask(image, mask,(0,255,0), 0.8)